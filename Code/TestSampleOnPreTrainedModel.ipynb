{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35621e83",
   "metadata": {},
   "source": [
    "### Before you run the file make sure you change the path of the following\n",
    "> test_sample_path\n",
    "> saved_model_path, \n",
    "> model name and num_classes here \"model = torchvision.models.resnet18(pretrained=False, num_classes = 2)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c1f595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100_1_2_20170112222336458.jpg.chip.jpg: 0\n",
      "110_0_2_20170112223734562.jpg.chip.jpg: 0\n",
      "14_0_0_20170110224445654.jpg.chip.jpg: 1\n",
      "14_0_0_20170110224528797.jpg.chip.jpg: 1\n",
      "17_0_0_20170103201439825.jpg.chip.jpg: 1\n",
      "17_1_1_20170112230710598.jpg.chip.jpg: 1\n",
      "18_1_1_20170116000609057.jpg.chip.jpg: 1\n",
      "1_0_2_20161219203112116.jpg.chip.jpg: 1\n",
      "1_0_3_20161219230224536.jpg.chip.jpg: 1\n",
      "1_0_3_20161220142918568.jpg.chip.jpg: 1\n",
      "1_1_0_20170109191148861.jpg.chip.jpg: 1\n",
      "20_1_2_20170116170358089.jpg.chip.jpg: 1\n",
      "21_1_3_20170119154352346.jpg.chip.jpg: 1\n",
      "22_0_1_20170113132548672.jpg.chip.jpg: 1\n",
      "22_1_1_20170113010336430.jpg.chip.jpg: 1\n",
      "22_1_4_20170103233857003.jpg.chip.jpg: 1\n",
      "24_0_0_20170117140958984.jpg.chip.jpg: 1\n",
      "24_0_0_20170119150204399.jpg.chip.jpg: 1\n",
      "24_0_2_20170116172518044.jpg.chip.jpg: 1\n",
      "24_0_3_20170119164638750.jpg.chip.jpg: 1\n",
      "24_0_3_20170120133910528.jpg.chip.jpg: 1\n",
      "24_1_4_20170103225201704.jpg.chip.jpg: 1\n",
      "25_0_3_20170119171240216.jpg.chip.jpg: 1\n",
      "25_1_0_20170117141803697.jpg.chip.jpg: 1\n",
      "25_1_1_20170117164610754.jpg.chip.jpg: 1\n",
      "25_1_3_20170119172137400.jpg.chip.jpg: 1\n",
      "26_0_1_20170113135240994.jpg.chip.jpg: 1\n",
      "26_0_1_20170116205301942.jpg.chip.jpg: 0\n",
      "26_0_1_20170116210257827.jpg.chip.jpg: 1\n",
      "26_0_1_20170116210446985.jpg.chip.jpg: 1\n",
      "26_0_1_20170117195155997.jpg.chip.jpg: 1\n",
      "26_0_4_20170117195456708.jpg.chip.jpg: 0\n",
      "26_0_4_20170117200431437.jpg.chip.jpg: 1\n",
      "26_1_0_20170103182456297.jpg.chip.jpg: 0\n",
      "26_1_0_20170116184725493.jpg.chip.jpg: 0\n",
      "26_1_1_20170112235926962.jpg.chip.jpg: 1\n",
      "26_1_3_20170117174319919.jpg.chip.jpg: 1\n",
      "26_1_3_20170119192323474.jpg.chip.jpg: 1\n",
      "26_1_3_20170119192328849.jpg.chip.jpg: 1\n",
      "26_1_4_20170117154047070.jpg.chip.jpg: 1\n",
      "26_1_4_20170117174505182.jpg.chip.jpg: 1\n",
      "26_1_4_20170117200341157.jpg.chip.jpg: 1\n",
      "27_0_0_20170117010049965.jpg.chip.jpg: 1\n",
      "27_0_1_20170113135622875.jpg.chip.jpg: 1\n",
      "27_1_1_20170109131744869.jpg.chip.jpg: 1\n",
      "27_1_1_20170117164706491.jpg.chip.jpg: 1\n",
      "27_1_3_20170119163731380.jpg.chip.jpg: 1\n",
      "28_0_1_20170109012501213.jpg.chip.jpg: 1\n",
      "28_0_1_20170116213517627.jpg.chip.jpg: 0\n",
      "28_0_1_20170117022047979.jpg.chip.jpg: 1\n",
      "28_0_3_20170119194509114.jpg.chip.jpg: 1\n",
      "2_0_2_20161219140905480.jpg.chip.jpg: 1\n",
      "30_1_0_20170117000354691.jpg.chip.jpg: 0\n",
      "30_1_0_20170117171346533.jpg.chip.jpg: 1\n",
      "30_1_1_20170116153114714.jpg.chip.jpg: 1\n",
      "31_0_2_20170116170847276.jpg.chip.jpg: 1\n",
      "31_1_4_20170117203017127.jpg.chip.jpg: 0\n",
      "32_0_0_20170116030520611.jpg.chip.jpg: 0\n",
      "32_0_0_20170116180259328.jpg.chip.jpg: 1\n",
      "35_1_0_20170104165729457.jpg.chip.jpg: 0\n",
      "36_0_4_20170117203502182.jpg.chip.jpg: 0\n",
      "36_1_0_20170103182343482.jpg.chip.jpg: 0\n",
      "37_1_1_20170116021920799.jpg.chip.jpg: 1\n",
      "38_1_0_20170117154129371.jpg.chip.jpg: 0\n",
      "38_1_1_20170116223105812.jpg.chip.jpg: 1\n",
      "38_1_4_20170117203741155.jpg.chip.jpg: 0\n",
      "39_0_0_20170117184953833.jpg.chip.jpg: 0\n",
      "3_1_2_20161219204943868.jpg.chip.jpg: 1\n",
      "40_0_0_20170109012159348.jpg.chip.jpg: 0\n",
      "40_0_2_20170116191940772.jpg.chip.jpg: 0\n",
      "40_1_3_20170104220757598.jpg.chip.jpg: 0\n",
      "41_1_0_20170109140858702.jpg.chip.jpg: 0\n",
      "44_0_0_20170104201051081.jpg.chip.jpg: 0\n",
      "44_0_3_20170119195210483.jpg.chip.jpg: 0\n",
      "45_0_0_20170120220558289.jpg.chip.jpg: 0\n",
      "46_0_1_20170113152154248.jpg.chip.jpg: 0\n",
      "4_1_2_20161219141829689.jpg.chip.jpg: 1\n",
      "50_0_4_20170104210650526.jpg.chip.jpg: 0\n",
      "53_0_0_20170104184408718.jpg.chip.jpg: 0\n",
      "54_0_1_20170113185033415.jpg.chip.jpg: 0\n",
      "54_0_2_20170116193514951.jpg.chip.jpg: 0\n",
      "54_0_3_20170111202045698.jpg.chip.jpg: 1\n",
      "54_0_3_20170119211306371.jpg.chip.jpg: 0\n",
      "54_1_3_20170104220907782.jpg.chip.jpg: 0\n",
      "55_1_3_20170119195255556.jpg.chip.jpg: 0\n",
      "59_0_0_20170104213214717.jpg.chip.jpg: 0\n",
      "5_0_0_20170110215706020.jpg.chip.jpg: 1\n",
      "5_0_3_20161220223303987.jpg.chip.jpg: 1\n",
      "60_0_0_20170104185553854.jpg.chip.jpg: 0\n",
      "60_0_3_20170119205938048.jpg.chip.jpg: 0\n",
      "61_0_2_20170104210058436.jpg.chip.jpg: 0\n",
      "61_1_0_20170117174758733.jpg.chip.jpg: 0\n",
      "65_0_0_20170117191827251.jpg.chip.jpg: 0\n",
      "6_0_2_20161219190713643.jpg.chip.jpg: 1\n",
      "6_1_4_20170104010006062.jpg.chip.jpg: 1\n",
      "73_0_1_20170117195318257.jpg.chip.jpg: 0\n",
      "85_1_0_20170110183721942.jpg.chip.jpg: 0\n",
      "8_0_0_20170110215618155.jpg.chip.jpg: 1\n",
      "8_1_0_20170109201746036.jpg.chip.jpg: 1\n",
      "92_1_0_20170110183357210.jpg.chip.jpg: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "test_sample_path = 'D:/ConcordiaU/Winter 23/AI/Project/Datasets/100TestSample/UTKFace/'\n",
    "\n",
    "saved_model_path = 'C:/Users/suppu/Downloads/UTKFace-RESNET.pth'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False, num_classes = 2)\n",
    "model.load_state_dict(torch.load(saved_model_path))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for filename in os.listdir(test_sample_path):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        image = Image.open(os.path.join(test_sample_path, filename))\n",
    "\n",
    "        image = transform(image)\n",
    "\n",
    "        image = image.unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        print(f'{filename}: {predicted.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a70f5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
